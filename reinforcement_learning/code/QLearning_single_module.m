% cooperative_regions.m
% Jodie Simkoff

% This function takes in a sidewalk, i.e. as generated by
% QLearning_sidewalk_modules.m, and trains a single modules on this sidewalk.
% The module's Q matrix is updated according to rewards/penalties related
% to all three objectives (litter collection, obstacle avoidance,
% end-reaching.)

function[Qsingle, singlemod_score,singlemod_paths] =  QLearning_single_module(sidewalk)
NUM_ITER = 100;


% build sidewalk with rewards and obstacles
W = size(sidewalk,1); 
L = size(sidewalk,2);

startX = 1; startY = 4;
sidewalk(startY, startX) = 80;

% save a copy of new sidewalk
sidewalk_new = sidewalk; 

% create Q matrix - randomly intialized from uniform dist
Q = rand(W,L,5);
alpha = 0.9; gamma = 0.5;
score_track = [];
figure();

for iter = 1:NUM_ITER
    sidewalk = sidewalk_new;
    score = 0;
    
    fig = imagesc(sidewalk); hold on;
    set(gcf, 'Position', [300, 300, 900, 400])
    set(gca,'xtick',[],'ytick',[]);
    title(iter)

    currX = startX ;
    currY = startY;
    pathk = [startX startY];
    pause(1)
    while currX < L
        
        pause(0.2);   
       sidewalk(currY,currX) = 0;
       if iter < 20
           action = ceil(5*rand);
       else
           [val,index] = max(Q(currY,currX,:));
           [xx,yy] = find(Q(currY,currX,:) == val);
           action = index;
       end
       prvX = currX; prvY = currY;
       
       [newX,newY] = move(currX,currY,action);
       
       currX = newX; 
       if newY <= W && newY >= 1
            currY = newY;
       end
        pathk = [pathk; currX currY];
       
       if sidewalk(currY,currX) == 160
           score = score+3;
           reward = 3  +  currX - prvX;
       elseif sidewalk(currY,currX) == 20
           reward = -1 +  currX - prvX;
           score = score-1;
       elseif sidewalk(currY,currX) == 200
           reward = 1000;
       else
           reward =  currX - prvX;
       end
               
       
       Q(prvY,prvX,action) = Q(prvY,prvX,action) + ...
           alpha*(reward+gamma*max(Q(currY,currX,:)) - Q(prvY,prvX,action));
       
       sidewalk(currY,currX) = 80;
       
       imagesc(sidewalk);
      
       
       
    end
singlemod_score(iter) = score;
fprintf('iter %d score: %d\n',iter,score)

singlemod_paths{iter} = pathk;
end
Qsingle = Q;
end    
function [newX,newY] = move(currX,currY,action)
    if action == 1 % go north
        newY = currY + 1;
        newX = currX;
    elseif action == 2 % go northeast
        newY = currY + 1;
        newX = currX + 1;
    elseif action == 3 % go east
        newY = currY;
        newX = currX + 1;
    elseif action == 4 % go southeast
        newY = currY - 1;
        newX = currX + 1;
    elseif action == 5 % go south
        newY = currY - 1;
        newX = currX;
    end
end


